{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import json \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, time\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from time import process_time \n",
    "\n",
    "def compute_HLVVW(df):\n",
    "    High = df['Price'].max()\n",
    "    Low = df['Price'].min()\n",
    "    Volume = df.Volume.iloc[-1]\n",
    "    Close = df.Price.iloc[-1]\n",
    "    df[\"VWAP\"] = (Volume * ((High + Low + Close) /3)) / Volume\n",
    "    return df\n",
    "\n",
    "def tickRule(df):\n",
    "    df['TickRule'] = 0\n",
    "    for i in range(0,len(df)):                          \n",
    "        if df.Price.iloc[i] > df.Price.iloc[i-1]:\n",
    "            df.TickRule.iloc[i] = 1 \n",
    "        elif df.Price.iloc[i] < df.Price.iloc[i-1]:\n",
    "            df.TickRule.iloc[i] = -1 \n",
    "        else: \n",
    "            df.TickRule.iloc[i] = df.TickRule.iloc[i-1]\n",
    "    df = df.assign(TickRule = df['TickRule'].cumsum())\n",
    "    return df\n",
    "                    \n",
    "# Choose to calculate volume as the division of the \n",
    "    # multiplication of the average ticks per day and their\n",
    "        # respective bid-ask volumes average.\n",
    "        # Considering that 80 bars per day in a normal day are filled by 2.3 million shares \n",
    "            # every 5 minutes.\n",
    "\n",
    "# Following the same path, tick bars equals the division of 80 and the\n",
    "    # division of the length of the data and the length of each day's data (tick-by-tick)\n",
    "def thresholds(df,threshold):\n",
    "    df = df.set_index('timestamp').astype(\n",
    "        {'bid_vol':'int64', 'ask_vol':'int64','date':'datetime64'}).reset_index()\n",
    "    total_ticks = len(df)\n",
    "    Day_grp = df.groupby(['date'])\n",
    "\n",
    "    Tick_per_bar = round((total_ticks / len(Day_grp)) / threshold)\n",
    "    Vol_per_bar = round(((total_ticks / len(Day_grp))* (\n",
    "        Day_grp.mean()['ask_vol'] + Day_grp.mean()['bid_vol']  / 2).mean())/ threshold)\n",
    "    return [Tick_per_bar, Vol_per_bar]\n",
    "\n",
    "def Variables(df):\n",
    "    df =  df.assign(Volume = df['bid_vol'].cumsum() + df['ask_vol'].cumsum(),\n",
    "                        Price = ((df['ask_vol'] * df['ask'] + df['bid_vol'] * df['bid'])\n",
    "                                / (df['ask_vol'] + df['bid_vol'])),\n",
    "                         MidPrice = (df['bid'] + df['ask'])/ 2,\n",
    "                        Spread  = df['ask'] - df['bid'],\n",
    "                       SpreadCm = (df['ask'] - df['bid']).cumsum()) \n",
    "    df = tickRule(df)\n",
    "\n",
    "    #  The observed prices are the result of sequential trading against the bid-ask spread\n",
    "    df = df.assign(ObservedPrice = df['Price'] + df['TickRule']*df['Spread'])\n",
    "    df = df.set_index('timestamp').astype(\n",
    "        {'bid_vol':'int64', 'ask_vol':'int64',\n",
    "         'Volume':'int64', 'Price':'float64', 'ObservedPrice':'float64'}).reset_index()\n",
    "    return df\n",
    "\n",
    "\n",
    "def Volume_Bars(df):\n",
    "    New_bar = Variables(df)\n",
    "    Volume_Bars = pd.DataFrame(columns = ['timestamp', 'bid', 'ask', 'bid_vol', \n",
    "                                         'ask_vol', 'Volume','Price', 'MidPrice', \n",
    "                                         'Spread', 'SpreadCm', 'TickRule', 'ObservedPrice'])\n",
    "\n",
    "#     Vol_per_bar = thresholds(data2,80)[1]# from instrument info table pull volperbar \n",
    "    \n",
    "    Vol_per_bar = 5000000\n",
    "    futureBar = pd.DataFrame(columns = ['timestamp','bid', 'ask', 'bid_vol','ask_vol'])\n",
    "    \n",
    "    while len(New_bar[New_bar['Volume'] >= Vol_per_bar]) > 1:\n",
    "        i = New_bar[New_bar['Volume'] >= Vol_per_bar].index[0]\n",
    "        Volume_Bars = Volume_Bars.append(compute_HLVVW(New_bar.iloc[:i]).iloc[-1])\n",
    "        deprecatedBar = New_bar.iloc[:i]\n",
    "        thirdQ = np.quantile(deprecatedBar['Volume'], .75).astype(int)\n",
    "        futureBar = New_bar[New_bar['Volume'] >= thirdQ]\n",
    "        futureBar = futureBar.drop([ 'Volume', 'Price', 'MidPrice',\n",
    "                                  'Spread', 'SpreadCm', 'TickRule', 'ObservedPrice'],axis = 1)\n",
    "        New_bar = Variables(futureBar)\n",
    "    \n",
    "    if (len(Volume_Bars) == 0) & (len(futureBar) == 0):\n",
    "        futureBar = df\n",
    "        \n",
    "    return [Volume_Bars,futureBar]\n",
    "\n",
    "def Tick_Bars(df):\n",
    "    New_bar = Variables(df)\n",
    "    Tick_Bars = pd.DataFrame(columns = ['timestamp', 'bid', 'ask', 'bid_vol', \n",
    "                                         'ask_vol', 'Volume','Price', 'MidPrice', \n",
    "                                         'Spread', 'SpreadCm', 'TickRule', 'ObservedPrice'])\n",
    "\n",
    "#     Tick_per_bar = thresholds(data2,threshold)[1]# from instrument info table pull volperbar \n",
    "    Tick_per_bar = 629\n",
    "\n",
    "    futureBar = pd.DataFrame(columns = ['timestamp','bid', 'ask', 'bid_vol','ask_vol'])\n",
    "   \n",
    "    while len(New_bar) > Tick_per_bar:\n",
    "        i = New_bar[New_bar.index >= Tick_per_bar].index[0]\n",
    "        Tick_Bars = Tick_Bars.append(compute_HLVVW(New_bar.iloc[:i]).iloc[-1])\n",
    "        deprecatedBar = New_bar.iloc[:i]\n",
    "        thirdQ = np.quantile(deprecatedBar.index[-1], .75).astype(int)\n",
    "        futureBar = New_bar[New_bar.index >= thirdQ]\n",
    "        futureBar = futureBar.drop([ 'Volume', 'Price', 'MidPrice',\n",
    "                                  'Spread', 'SpreadCm', 'TickRule', 'ObservedPrice'],axis = 1)\n",
    "        New_bar = Variables(futureBar)\n",
    "        \n",
    "    if (len(Tick_Bars) == 0) & (len(futureBar) == 0):\n",
    "        futureBar = df\n",
    "        \n",
    "    return [Tick_Bars,futureBar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instruments ID \n",
    "# Api to get the list of instruments \n",
    "response2 = requests.get('https://freeserv.dukascopy.com/2.0/?path=api/instrumentList',\n",
    "                        params= {'key' : 'rup1doorqo000000'})\n",
    "\n",
    "# pd.DataFrame(response2.json()).iloc[0,1]\n",
    "FAANG = {\"Apple\":\"70002\" ,\"Facebook\":\"70094\",\"Amazon\":\"70022\",\"Google\":\"70118\",\"Netflix\":\"70178\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "# for loop for each day of 2019 \n",
    "# Start the stopwatch / counter  \n",
    "t1_start = process_time()  \n",
    "\n",
    "instruments = FAANG[\"Netflix\"]\n",
    "# # empty dataframe with columns: ['timestamp','bid', 'ask', 'bid_vol','ask_vol']\n",
    "# la3 = pd.DataFrame(columns = ['timestamp','bid', 'ask', 'bid_vol','ask_vol'])\n",
    "\n",
    "# vols =  pd.DataFrame(columns = ['timestamp', 'bid', 'ask', 'bid_vol', \n",
    "#                                      'ask_vol',  'Volume','Price', 'MidPrice', \n",
    "#                                      'Spread', 'SpreadCm', 'TickRule', 'ObservedPrice'])\n",
    "\n",
    "# ticks =  pd.DataFrame(columns = ['timestamp', 'bid', 'ask', 'bid_vol', \n",
    "#                                      'ask_vol', 'Volume','Price', 'MidPrice', \n",
    "#                                      'Spread', 'SpreadCm', 'TickRule', 'ObservedPrice'])\n",
    "\n",
    "# futureBarTick = pd.DataFrame(columns = ['timestamp','bid', 'ask', 'bid_vol','ask_vol'])\n",
    "# futureBarVolume = pd.DataFrame(columns = ['timestamp','bid', 'ask', 'bid_vol','ask_vol'])\n",
    "\n",
    "# for each number between 199 - 150 (part of the 365 days of the year) going in negative way\n",
    "for i in list(range(102,0,-1)):\n",
    "    # substract from the 01-01-2020 the days that i equals\n",
    "    date = datetime(2020, 1, 1) - timedelta(days=i)\n",
    "\n",
    "    # converts date into timestamp and adds 9 hs and 30 minutes, \n",
    "        # and multiplies * 1000 to get miliseconds, while using int() to convert to integer\n",
    "    start = int(datetime.timestamp(date + timedelta(hours = 9, minutes = 30)) * 1000)\n",
    "    end = int(datetime.timestamp(date + timedelta(hours = 9, minutes = 35)) * 1000)\n",
    "\n",
    "#     if len(pd.DataFrame(pd.DataFrame(requests.get('https://freeserv.dukascopy.com/2.0/?path=api/historicalPrices', \n",
    "#                                 params={'key' : 'rup1doorqo000000','instrument':instruments,\n",
    "#                                         'timeFrame':'tick','count':'5000',\n",
    "#                                         'start':start, 'end':end}).json())['ticks'].tolist())) > 0:\n",
    "#         # while the datetime is less than 15:56 hs\n",
    "    while datetime.fromtimestamp(end/1000).time() < time(hour = 15, minute = 56):\n",
    "\n",
    "        # set parameter conditions, the key here is that start and end are always different\n",
    "        parameters = {'key' : 'rup1doorqo000000','instrument':instruments,'timeFrame':'tick','count':'5000',\n",
    "           'start':start, 'end':end}\n",
    "\n",
    "        # api pull request\n",
    "        response = requests.get('https://freeserv.dukascopy.com/2.0/?path=api/historicalPrices', \n",
    "                                params=parameters) \n",
    "\n",
    "        # convert pull request into json file\n",
    "        la = pd.DataFrame(response.json())\n",
    "\n",
    "        # gets tick data from json file and converts it to list and then df\n",
    "        pe = pd.DataFrame(la['ticks'].tolist())\n",
    "\n",
    "        la3 = pd.concat([la3,pe])\n",
    "\n",
    "        for k in range(len(pe)):\n",
    "            pe['timestamp'].iloc[k] = datetime.fromtimestamp(pe['timestamp'].iloc[k]/1000)\n",
    "\n",
    "#             pe = pe.assign(date = [d.date() for d in pe['timestamp']])\n",
    "\n",
    "        vbars = Volume_Bars(pd.concat([futureBarVolume,pe]))\n",
    "        tbars = Tick_Bars(pd.concat([futureBarTick,pe]))\n",
    "\n",
    "        futureBarVolume = vbars[1]\n",
    "        futureBarTick = tbars[1]\n",
    "\n",
    "        vols = pd.concat([vols, vbars[0]])\n",
    "        ticks = pd.concat([ticks, tbars[0]])\n",
    "\n",
    "        # adds five minutes to both start and end of the pull request\n",
    "        start = int(datetime.timestamp(datetime.fromtimestamp(start/1000) + timedelta(minutes = 5)) * 1000)\n",
    "        end = int(datetime.timestamp(datetime.fromtimestamp(end/1000) + timedelta(minutes = 5)) * 1000)\n",
    "\n",
    "# converts timetstamp to datetime and substracts 5 vs\n",
    "la3['timestamp'] = pd.to_datetime(la3['timestamp'], unit='ms') - timedelta(hours= 5)\n",
    "la3 = la3.assign(date = [d.date() for d in la3['timestamp']])\n",
    "la3['Instrument'] = \"Netflix\"\n",
    "\n",
    "# Stop the stopwatch / counter \n",
    "t1_stop = process_time() \n",
    "\n",
    "print(\"Elapsed time:\", t1_stop, t1_start)  \n",
    "print(\"Elapsed time during the whole program in seconds:\", \n",
    "                                     t1_stop-t1_start)\n",
    "la3.to_csv(\"Netflix\" + \"MainData.csv\")\n",
    "ticks['Instrument'] = \"Netflix\"\n",
    "vols['Instrument'] = \"Netflix\"\n",
    "ticks.to_csv(\"Netflix\" + \"ticks.csv\")\n",
    "vols.to_csv(\"Netflix\"+ \"vols.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "la3.to_csv(\"Netflix\" + \"MainData.csv\")\n",
    "ticks['Instrument'] = \"Netflix\"\n",
    "vols['Instrument'] = \"Netflix\"\n",
    "ticks.to_csv(\"Netflix\" + \"ticks.csv\")\n",
    "vols.to_csv(\"Netflix\"+ \"vols.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363 2019-01-03 00:00:00\n",
      "362 2019-01-04 00:00:00\n",
      "361 2019-01-05 00:00:00\n",
      "360 2019-01-06 00:00:00\n",
      "359 2019-01-07 00:00:00\n",
      "358 2019-01-08 00:00:00\n",
      "357 2019-01-09 00:00:00\n",
      "356 2019-01-10 00:00:00\n",
      "355 2019-01-11 00:00:00\n",
      "354 2019-01-12 00:00:00\n",
      "353 2019-01-13 00:00:00\n",
      "352 2019-01-14 00:00:00\n",
      "351 2019-01-15 00:00:00\n",
      "350 2019-01-16 00:00:00\n",
      "349 2019-01-17 00:00:00\n",
      "348 2019-01-18 00:00:00\n",
      "347 2019-01-19 00:00:00\n",
      "346 2019-01-20 00:00:00\n",
      "345 2019-01-21 00:00:00\n",
      "344 2019-01-22 00:00:00\n",
      "343 2019-01-23 00:00:00\n",
      "342 2019-01-24 00:00:00\n",
      "341 2019-01-25 00:00:00\n",
      "340 2019-01-26 00:00:00\n",
      "339 2019-01-27 00:00:00\n",
      "338 2019-01-28 00:00:00\n",
      "337 2019-01-29 00:00:00\n",
      "336 2019-01-30 00:00:00\n",
      "335 2019-01-31 00:00:00\n",
      "334 2019-02-01 00:00:00\n",
      "333 2019-02-02 00:00:00\n",
      "332 2019-02-03 00:00:00\n",
      "331 2019-02-04 00:00:00\n",
      "330 2019-02-05 00:00:00\n",
      "329 2019-02-06 00:00:00\n",
      "328 2019-02-07 00:00:00\n",
      "327 2019-02-08 00:00:00\n",
      "326 2019-02-09 00:00:00\n",
      "325 2019-02-10 00:00:00\n",
      "324 2019-02-11 00:00:00\n",
      "323 2019-02-12 00:00:00\n",
      "322 2019-02-13 00:00:00\n",
      "321 2019-02-14 00:00:00\n",
      "320 2019-02-15 00:00:00\n",
      "319 2019-02-16 00:00:00\n",
      "318 2019-02-17 00:00:00\n",
      "317 2019-02-18 00:00:00\n",
      "316 2019-02-19 00:00:00\n",
      "315 2019-02-20 00:00:00\n",
      "314 2019-02-21 00:00:00\n",
      "313 2019-02-22 00:00:00\n",
      "312 2019-02-23 00:00:00\n",
      "311 2019-02-24 00:00:00\n",
      "310 2019-02-25 00:00:00\n",
      "309 2019-02-26 00:00:00\n",
      "308 2019-02-27 00:00:00\n",
      "307 2019-02-28 00:00:00\n",
      "306 2019-03-01 00:00:00\n",
      "305 2019-03-02 00:00:00\n",
      "304 2019-03-03 00:00:00\n",
      "303 2019-03-04 00:00:00\n",
      "302 2019-03-05 00:00:00\n",
      "301 2019-03-06 00:00:00\n",
      "300 2019-03-07 00:00:00\n",
      "299 2019-03-08 00:00:00\n",
      "298 2019-03-09 00:00:00\n",
      "297 2019-03-10 00:00:00\n",
      "296 2019-03-11 00:00:00\n",
      "295 2019-03-12 00:00:00\n",
      "294 2019-03-13 00:00:00\n",
      "293 2019-03-14 00:00:00\n",
      "292 2019-03-15 00:00:00\n",
      "291 2019-03-16 00:00:00\n",
      "290 2019-03-17 00:00:00\n",
      "289 2019-03-18 00:00:00\n",
      "288 2019-03-19 00:00:00\n",
      "287 2019-03-20 00:00:00\n",
      "286 2019-03-21 00:00:00\n",
      "285 2019-03-22 00:00:00\n",
      "284 2019-03-23 00:00:00\n",
      "283 2019-03-24 00:00:00\n",
      "282 2019-03-25 00:00:00\n",
      "281 2019-03-26 00:00:00\n",
      "280 2019-03-27 00:00:00\n",
      "279 2019-03-28 00:00:00\n",
      "278 2019-03-29 00:00:00\n",
      "277 2019-03-30 00:00:00\n",
      "276 2019-03-31 00:00:00\n",
      "275 2019-04-01 00:00:00\n",
      "274 2019-04-02 00:00:00\n",
      "273 2019-04-03 00:00:00\n",
      "272 2019-04-04 00:00:00\n",
      "271 2019-04-05 00:00:00\n",
      "270 2019-04-06 00:00:00\n",
      "269 2019-04-07 00:00:00\n",
      "268 2019-04-08 00:00:00\n",
      "267 2019-04-09 00:00:00\n",
      "266 2019-04-10 00:00:00\n",
      "265 2019-04-11 00:00:00\n",
      "264 2019-04-12 00:00:00\n",
      "263 2019-04-13 00:00:00\n",
      "262 2019-04-14 00:00:00\n",
      "261 2019-04-15 00:00:00\n",
      "260 2019-04-16 00:00:00\n",
      "259 2019-04-17 00:00:00\n",
      "258 2019-04-18 00:00:00\n",
      "257 2019-04-19 00:00:00\n",
      "256 2019-04-20 00:00:00\n",
      "255 2019-04-21 00:00:00\n",
      "254 2019-04-22 00:00:00\n",
      "253 2019-04-23 00:00:00\n",
      "252 2019-04-24 00:00:00\n",
      "251 2019-04-25 00:00:00\n",
      "250 2019-04-26 00:00:00\n",
      "249 2019-04-27 00:00:00\n",
      "248 2019-04-28 00:00:00\n",
      "247 2019-04-29 00:00:00\n",
      "246 2019-04-30 00:00:00\n",
      "245 2019-05-01 00:00:00\n",
      "244 2019-05-02 00:00:00\n",
      "243 2019-05-03 00:00:00\n",
      "242 2019-05-04 00:00:00\n",
      "241 2019-05-05 00:00:00\n",
      "240 2019-05-06 00:00:00\n",
      "239 2019-05-07 00:00:00\n",
      "238 2019-05-08 00:00:00\n",
      "237 2019-05-09 00:00:00\n",
      "236 2019-05-10 00:00:00\n",
      "235 2019-05-11 00:00:00\n",
      "234 2019-05-12 00:00:00\n",
      "233 2019-05-13 00:00:00\n",
      "232 2019-05-14 00:00:00\n",
      "231 2019-05-15 00:00:00\n",
      "230 2019-05-16 00:00:00\n",
      "229 2019-05-17 00:00:00\n",
      "228 2019-05-18 00:00:00\n",
      "227 2019-05-19 00:00:00\n",
      "226 2019-05-20 00:00:00\n",
      "225 2019-05-21 00:00:00\n",
      "224 2019-05-22 00:00:00\n",
      "223 2019-05-23 00:00:00\n",
      "222 2019-05-24 00:00:00\n",
      "221 2019-05-25 00:00:00\n",
      "220 2019-05-26 00:00:00\n",
      "219 2019-05-27 00:00:00\n",
      "218 2019-05-28 00:00:00\n",
      "217 2019-05-29 00:00:00\n",
      "216 2019-05-30 00:00:00\n",
      "215 2019-05-31 00:00:00\n",
      "214 2019-06-01 00:00:00\n",
      "213 2019-06-02 00:00:00\n",
      "212 2019-06-03 00:00:00\n",
      "211 2019-06-04 00:00:00\n",
      "210 2019-06-05 00:00:00\n",
      "209 2019-06-06 00:00:00\n",
      "208 2019-06-07 00:00:00\n",
      "207 2019-06-08 00:00:00\n",
      "206 2019-06-09 00:00:00\n",
      "205 2019-06-10 00:00:00\n",
      "204 2019-06-11 00:00:00\n",
      "203 2019-06-12 00:00:00\n",
      "202 2019-06-13 00:00:00\n",
      "201 2019-06-14 00:00:00\n",
      "200 2019-06-15 00:00:00\n",
      "199 2019-06-16 00:00:00\n",
      "198 2019-06-17 00:00:00\n",
      "197 2019-06-18 00:00:00\n",
      "196 2019-06-19 00:00:00\n",
      "195 2019-06-20 00:00:00\n",
      "194 2019-06-21 00:00:00\n",
      "193 2019-06-22 00:00:00\n",
      "192 2019-06-23 00:00:00\n",
      "191 2019-06-24 00:00:00\n",
      "190 2019-06-25 00:00:00\n",
      "189 2019-06-26 00:00:00\n",
      "188 2019-06-27 00:00:00\n",
      "187 2019-06-28 00:00:00\n",
      "186 2019-06-29 00:00:00\n",
      "185 2019-06-30 00:00:00\n",
      "184 2019-07-01 00:00:00\n",
      "183 2019-07-02 00:00:00\n",
      "182 2019-07-03 00:00:00\n",
      "181 2019-07-04 00:00:00\n",
      "180 2019-07-05 00:00:00\n",
      "179 2019-07-06 00:00:00\n",
      "178 2019-07-07 00:00:00\n",
      "177 2019-07-08 00:00:00\n",
      "176 2019-07-09 00:00:00\n",
      "175 2019-07-10 00:00:00\n",
      "174 2019-07-11 00:00:00\n",
      "173 2019-07-12 00:00:00\n",
      "172 2019-07-13 00:00:00\n",
      "171 2019-07-14 00:00:00\n",
      "170 2019-07-15 00:00:00\n",
      "169 2019-07-16 00:00:00\n",
      "168 2019-07-17 00:00:00\n",
      "167 2019-07-18 00:00:00\n",
      "166 2019-07-19 00:00:00\n",
      "165 2019-07-20 00:00:00\n",
      "164 2019-07-21 00:00:00\n",
      "163 2019-07-22 00:00:00\n",
      "162 2019-07-23 00:00:00\n",
      "161 2019-07-24 00:00:00\n",
      "160 2019-07-25 00:00:00\n",
      "159 2019-07-26 00:00:00\n",
      "158 2019-07-27 00:00:00\n",
      "157 2019-07-28 00:00:00\n",
      "156 2019-07-29 00:00:00\n",
      "155 2019-07-30 00:00:00\n",
      "154 2019-07-31 00:00:00\n",
      "153 2019-08-01 00:00:00\n",
      "152 2019-08-02 00:00:00\n",
      "151 2019-08-03 00:00:00\n",
      "150 2019-08-04 00:00:00\n",
      "149 2019-08-05 00:00:00\n",
      "148 2019-08-06 00:00:00\n",
      "147 2019-08-07 00:00:00\n",
      "146 2019-08-08 00:00:00\n",
      "145 2019-08-09 00:00:00\n",
      "144 2019-08-10 00:00:00\n",
      "143 2019-08-11 00:00:00\n",
      "142 2019-08-12 00:00:00\n",
      "141 2019-08-13 00:00:00\n",
      "140 2019-08-14 00:00:00\n",
      "139 2019-08-15 00:00:00\n",
      "138 2019-08-16 00:00:00\n",
      "137 2019-08-17 00:00:00\n",
      "136 2019-08-18 00:00:00\n",
      "135 2019-08-19 00:00:00\n",
      "134 2019-08-20 00:00:00\n",
      "133 2019-08-21 00:00:00\n",
      "132 2019-08-22 00:00:00\n",
      "131 2019-08-23 00:00:00\n",
      "130 2019-08-24 00:00:00\n",
      "129 2019-08-25 00:00:00\n",
      "128 2019-08-26 00:00:00\n",
      "127 2019-08-27 00:00:00\n",
      "126 2019-08-28 00:00:00\n",
      "125 2019-08-29 00:00:00\n",
      "124 2019-08-30 00:00:00\n",
      "123 2019-08-31 00:00:00\n",
      "122 2019-09-01 00:00:00\n",
      "121 2019-09-02 00:00:00\n",
      "120 2019-09-03 00:00:00\n",
      "119 2019-09-04 00:00:00\n",
      "118 2019-09-05 00:00:00\n",
      "117 2019-09-06 00:00:00\n",
      "116 2019-09-07 00:00:00\n",
      "115 2019-09-08 00:00:00\n",
      "114 2019-09-09 00:00:00\n",
      "113 2019-09-10 00:00:00\n",
      "112 2019-09-11 00:00:00\n",
      "111 2019-09-12 00:00:00\n",
      "110 2019-09-13 00:00:00\n",
      "109 2019-09-14 00:00:00\n",
      "108 2019-09-15 00:00:00\n",
      "107 2019-09-16 00:00:00\n",
      "106 2019-09-17 00:00:00\n",
      "105 2019-09-18 00:00:00\n",
      "104 2019-09-19 00:00:00\n",
      "103 2019-09-20 00:00:00\n",
      "102 2019-09-21 00:00:00\n",
      "101 2019-09-22 00:00:00\n",
      "100 2019-09-23 00:00:00\n",
      "99 2019-09-24 00:00:00\n",
      "98 2019-09-25 00:00:00\n",
      "97 2019-09-26 00:00:00\n",
      "96 2019-09-27 00:00:00\n",
      "95 2019-09-28 00:00:00\n",
      "94 2019-09-29 00:00:00\n",
      "93 2019-09-30 00:00:00\n",
      "92 2019-10-01 00:00:00\n",
      "91 2019-10-02 00:00:00\n",
      "90 2019-10-03 00:00:00\n",
      "89 2019-10-04 00:00:00\n",
      "88 2019-10-05 00:00:00\n",
      "87 2019-10-06 00:00:00\n",
      "86 2019-10-07 00:00:00\n",
      "85 2019-10-08 00:00:00\n",
      "84 2019-10-09 00:00:00\n",
      "83 2019-10-10 00:00:00\n",
      "82 2019-10-11 00:00:00\n",
      "81 2019-10-12 00:00:00\n",
      "80 2019-10-13 00:00:00\n",
      "79 2019-10-14 00:00:00\n",
      "78 2019-10-15 00:00:00\n",
      "77 2019-10-16 00:00:00\n",
      "76 2019-10-17 00:00:00\n",
      "75 2019-10-18 00:00:00\n",
      "74 2019-10-19 00:00:00\n",
      "73 2019-10-20 00:00:00\n",
      "72 2019-10-21 00:00:00\n",
      "71 2019-10-22 00:00:00\n",
      "70 2019-10-23 00:00:00\n",
      "69 2019-10-24 00:00:00\n",
      "68 2019-10-25 00:00:00\n",
      "67 2019-10-26 00:00:00\n",
      "66 2019-10-27 00:00:00\n",
      "65 2019-10-28 00:00:00\n",
      "64 2019-10-29 00:00:00\n",
      "63 2019-10-30 00:00:00\n",
      "62 2019-10-31 00:00:00\n",
      "61 2019-11-01 00:00:00\n",
      "60 2019-11-02 00:00:00\n",
      "59 2019-11-03 00:00:00\n",
      "58 2019-11-04 00:00:00\n",
      "57 2019-11-05 00:00:00\n",
      "56 2019-11-06 00:00:00\n",
      "55 2019-11-07 00:00:00\n",
      "54 2019-11-08 00:00:00\n",
      "53 2019-11-09 00:00:00\n",
      "52 2019-11-10 00:00:00\n",
      "51 2019-11-11 00:00:00\n",
      "50 2019-11-12 00:00:00\n",
      "49 2019-11-13 00:00:00\n",
      "48 2019-11-14 00:00:00\n",
      "47 2019-11-15 00:00:00\n",
      "46 2019-11-16 00:00:00\n",
      "45 2019-11-17 00:00:00\n",
      "44 2019-11-18 00:00:00\n",
      "43 2019-11-19 00:00:00\n",
      "42 2019-11-20 00:00:00\n",
      "41 2019-11-21 00:00:00\n",
      "40 2019-11-22 00:00:00\n",
      "39 2019-11-23 00:00:00\n",
      "38 2019-11-24 00:00:00\n",
      "37 2019-11-25 00:00:00\n",
      "36 2019-11-26 00:00:00\n",
      "35 2019-11-27 00:00:00\n",
      "34 2019-11-28 00:00:00\n",
      "33 2019-11-29 00:00:00\n",
      "32 2019-11-30 00:00:00\n",
      "31 2019-12-01 00:00:00\n",
      "30 2019-12-02 00:00:00\n",
      "29 2019-12-03 00:00:00\n",
      "28 2019-12-04 00:00:00\n",
      "27 2019-12-05 00:00:00\n",
      "26 2019-12-06 00:00:00\n",
      "25 2019-12-07 00:00:00\n",
      "24 2019-12-08 00:00:00\n",
      "23 2019-12-09 00:00:00\n",
      "22 2019-12-10 00:00:00\n",
      "21 2019-12-11 00:00:00\n",
      "20 2019-12-12 00:00:00\n",
      "19 2019-12-13 00:00:00\n",
      "18 2019-12-14 00:00:00\n",
      "17 2019-12-15 00:00:00\n",
      "16 2019-12-16 00:00:00\n",
      "15 2019-12-17 00:00:00\n",
      "14 2019-12-18 00:00:00\n",
      "13 2019-12-19 00:00:00\n",
      "12 2019-12-20 00:00:00\n",
      "11 2019-12-21 00:00:00\n",
      "10 2019-12-22 00:00:00\n",
      "9 2019-12-23 00:00:00\n",
      "8 2019-12-24 00:00:00\n",
      "7 2019-12-25 00:00:00\n",
      "6 2019-12-26 00:00:00\n",
      "5 2019-12-27 00:00:00\n",
      "4 2019-12-28 00:00:00\n",
      "3 2019-12-29 00:00:00\n",
      "2 2019-12-30 00:00:00\n",
      "1 2019-12-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "for i in list(range(363,0,-1)):\n",
    "    # substract from the 01-01-2020 the days that i equals\n",
    "    print(i,datetime(2020, 1, 1) - timedelta(days=i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>bid</th>\n",
       "      <th>ask</th>\n",
       "      <th>bid_vol</th>\n",
       "      <th>ask_vol</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Price</th>\n",
       "      <th>MidPrice</th>\n",
       "      <th>Spread</th>\n",
       "      <th>SpreadCm</th>\n",
       "      <th>TickRule</th>\n",
       "      <th>ObservedPrice</th>\n",
       "      <th>VWAP</th>\n",
       "      <th>Instrument</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>2019-01-03 09:32:11.348</td>\n",
       "      <td>143.861</td>\n",
       "      <td>143.903</td>\n",
       "      <td>320</td>\n",
       "      <td>7500</td>\n",
       "      <td>4996890</td>\n",
       "      <td>143.901281</td>\n",
       "      <td>143.8820</td>\n",
       "      <td>0.042</td>\n",
       "      <td>48.643</td>\n",
       "      <td>-4</td>\n",
       "      <td>143.733281</td>\n",
       "      <td>144.106850</td>\n",
       "      <td>Netflix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>2019-01-03 09:34:09.836</td>\n",
       "      <td>144.157</td>\n",
       "      <td>144.203</td>\n",
       "      <td>10</td>\n",
       "      <td>7500</td>\n",
       "      <td>4993631</td>\n",
       "      <td>144.202939</td>\n",
       "      <td>144.1800</td>\n",
       "      <td>0.046</td>\n",
       "      <td>52.224</td>\n",
       "      <td>-30</td>\n",
       "      <td>142.822939</td>\n",
       "      <td>144.109951</td>\n",
       "      <td>Netflix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>2019-01-03 09:35:50.859</td>\n",
       "      <td>143.387</td>\n",
       "      <td>143.423</td>\n",
       "      <td>110</td>\n",
       "      <td>37</td>\n",
       "      <td>4993135</td>\n",
       "      <td>143.396061</td>\n",
       "      <td>143.4050</td>\n",
       "      <td>0.036</td>\n",
       "      <td>46.914</td>\n",
       "      <td>-20</td>\n",
       "      <td>142.676061</td>\n",
       "      <td>143.663894</td>\n",
       "      <td>Netflix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>2019-01-03 09:37:30.378</td>\n",
       "      <td>143.148</td>\n",
       "      <td>143.183</td>\n",
       "      <td>10</td>\n",
       "      <td>7500</td>\n",
       "      <td>4990689</td>\n",
       "      <td>143.182953</td>\n",
       "      <td>143.1655</td>\n",
       "      <td>0.035</td>\n",
       "      <td>47.246</td>\n",
       "      <td>10</td>\n",
       "      <td>143.532953</td>\n",
       "      <td>143.241480</td>\n",
       "      <td>Netflix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>2019-01-03 09:39:19.218</td>\n",
       "      <td>143.288</td>\n",
       "      <td>143.332</td>\n",
       "      <td>110</td>\n",
       "      <td>4</td>\n",
       "      <td>4987916</td>\n",
       "      <td>143.289544</td>\n",
       "      <td>143.3100</td>\n",
       "      <td>0.044</td>\n",
       "      <td>44.905</td>\n",
       "      <td>25</td>\n",
       "      <td>144.389544</td>\n",
       "      <td>143.222261</td>\n",
       "      <td>Netflix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>2019-09-20 14:08:51.249</td>\n",
       "      <td>267.197</td>\n",
       "      <td>267.283</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>4998000</td>\n",
       "      <td>267.240000</td>\n",
       "      <td>267.2400</td>\n",
       "      <td>0.086</td>\n",
       "      <td>320.632</td>\n",
       "      <td>-25</td>\n",
       "      <td>265.090000</td>\n",
       "      <td>267.010000</td>\n",
       "      <td>Netflix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>2019-09-20 14:38:03.559</td>\n",
       "      <td>268.858</td>\n",
       "      <td>268.952</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>4998000</td>\n",
       "      <td>268.905000</td>\n",
       "      <td>268.9050</td>\n",
       "      <td>0.094</td>\n",
       "      <td>230.222</td>\n",
       "      <td>-43</td>\n",
       "      <td>264.863000</td>\n",
       "      <td>268.281667</td>\n",
       "      <td>Netflix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>2019-09-20 15:05:22.845</td>\n",
       "      <td>270.118</td>\n",
       "      <td>270.192</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>4998000</td>\n",
       "      <td>270.155000</td>\n",
       "      <td>270.1550</td>\n",
       "      <td>0.074</td>\n",
       "      <td>233.354</td>\n",
       "      <td>79</td>\n",
       "      <td>276.001000</td>\n",
       "      <td>269.251667</td>\n",
       "      <td>Netflix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>2019-09-20 15:34:07.129</td>\n",
       "      <td>269.307</td>\n",
       "      <td>269.423</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>4998000</td>\n",
       "      <td>269.365000</td>\n",
       "      <td>269.3650</td>\n",
       "      <td>0.116</td>\n",
       "      <td>210.862</td>\n",
       "      <td>25</td>\n",
       "      <td>272.265000</td>\n",
       "      <td>269.578333</td>\n",
       "      <td>Netflix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>2019-09-20 15:52:57.703</td>\n",
       "      <td>269.728</td>\n",
       "      <td>269.802</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>4998000</td>\n",
       "      <td>269.765000</td>\n",
       "      <td>269.7650</td>\n",
       "      <td>0.074</td>\n",
       "      <td>171.424</td>\n",
       "      <td>83</td>\n",
       "      <td>275.907000</td>\n",
       "      <td>269.645000</td>\n",
       "      <td>Netflix</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9033 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   timestamp      bid      ask bid_vol ask_vol   Volume  \\\n",
       "887  2019-01-03 09:32:11.348  143.861  143.903     320    7500  4996890   \n",
       "983  2019-01-03 09:34:09.836  144.157  144.203      10    7500  4993631   \n",
       "937  2019-01-03 09:35:50.859  143.387  143.423     110      37  4993135   \n",
       "985  2019-01-03 09:37:30.378  143.148  143.183      10    7500  4990689   \n",
       "972  2019-01-03 09:39:19.218  143.288  143.332     110       4  4987916   \n",
       "...                      ...      ...      ...     ...     ...      ...   \n",
       "2498 2019-09-20 14:08:51.249  267.197  267.283    1000    1000  4998000   \n",
       "2498 2019-09-20 14:38:03.559  268.858  268.952    1000    1000  4998000   \n",
       "2498 2019-09-20 15:05:22.845  270.118  270.192    1000    1000  4998000   \n",
       "2498 2019-09-20 15:34:07.129  269.307  269.423    1000    1000  4998000   \n",
       "2498 2019-09-20 15:52:57.703  269.728  269.802    1000    1000  4998000   \n",
       "\n",
       "           Price  MidPrice  Spread  SpreadCm TickRule  ObservedPrice  \\\n",
       "887   143.901281  143.8820   0.042    48.643       -4     143.733281   \n",
       "983   144.202939  144.1800   0.046    52.224      -30     142.822939   \n",
       "937   143.396061  143.4050   0.036    46.914      -20     142.676061   \n",
       "985   143.182953  143.1655   0.035    47.246       10     143.532953   \n",
       "972   143.289544  143.3100   0.044    44.905       25     144.389544   \n",
       "...          ...       ...     ...       ...      ...            ...   \n",
       "2498  267.240000  267.2400   0.086   320.632      -25     265.090000   \n",
       "2498  268.905000  268.9050   0.094   230.222      -43     264.863000   \n",
       "2498  270.155000  270.1550   0.074   233.354       79     276.001000   \n",
       "2498  269.365000  269.3650   0.116   210.862       25     272.265000   \n",
       "2498  269.765000  269.7650   0.074   171.424       83     275.907000   \n",
       "\n",
       "            VWAP Instrument  \n",
       "887   144.106850    Netflix  \n",
       "983   144.109951    Netflix  \n",
       "937   143.663894    Netflix  \n",
       "985   143.241480    Netflix  \n",
       "972   143.222261    Netflix  \n",
       "...          ...        ...  \n",
       "2498  267.010000    Netflix  \n",
       "2498  268.281667    Netflix  \n",
       "2498  269.251667    Netflix  \n",
       "2498  269.578333    Netflix  \n",
       "2498  269.645000    Netflix  \n",
       "\n",
       "[9033 rows x 14 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vols"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
