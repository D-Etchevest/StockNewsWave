---
title: "Exploratory Analysis"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

This RMarkdown explores volume and tick bars parameter's volatility and strives to find the an average range of days pre & post news releases. The goal is to test for significance difference of no-news vs news days. 

The Exploratory is performed for Google. 

# Libraries 

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(lubridate)
library(ggplot2)
library(plotly)

setwd("C:/Users/Academica/Desktop/Internet Explorer/STU/Summer 2020/Capstone/Data")

```

# Functions 
```{r Functions, message=FALSE, warning=FALSE}

News <- function(instrument){
  setwd("C:/Users/Academica/Desktop/Internet Explorer/STU/Summer 2020/Capstone/Data")

  # News ####
  news <- read.csv('News - 2019-2020.csv', stringsAsFactors = FALSE) 
  news <- rename(news, "date" = "Ã¯..pubdate")
  news$date <- mdy_hm(news$date) 
  
  # This chunk finds the articles that refer specific <- y or integrate Google news.
  News <- news[c(grep(instrument,news$description)),] %>%
    filter(date > ymd_hms("2019-01-01 15:52:54") & date < ymd_hms("2019-06-14 15:52:54") &
             hour(date) > 10 & hour(date) < 14)
  News$date <- sort(News$date)
  News$dateDistance <- 0
  for (i in 2:nrow(News)){
    News$dateDistance[i] <- round(
      difftime( News$date[i], News$date[i-1],units = "hours"),digits = 2) }
#  cat("There are", nrow(News), "articles related to", instrument)
  return(News)
}

Bars <- function(csvTick,csvVol,News){
  setwd("C:/Users/Academica/Desktop/Internet Explorer/STU/Summer 2020/Capstone/Data")

  TickBars <- read.csv(csvTick) %>% rename("ticks" = "X") 
  TickBars$timestamp <- as.POSIXct(strptime(TickBars$timestamp, "%Y-%m-%d %H:%M"))
  #TickBars$timestamp <-   gsub(":00","",TickBars$timestamp)
  TickBars$SpreadCm <- TickBars$SpreadCm / 629
  TickBars$ObservedPrice <-  as.numeric(unlist( 
    TickBars['Price'] + TickBars['TickRule'] * (TickBars['Spread'] /2)))
  TickBars$Event <- ifelse(date(TickBars$timestamp) %in% date(News$date),"Yes","No")
  TickBars$Bar <- "Tick Bar"
  TickBars <- filter(TickBars, hour(timestamp) >= 10 & hour(timestamp) < 15)
  
  
  VolumeBars <- read.csv(csvVol) %>% rename("ticks" = "X")
  VolumeBars$timestamp <- as.POSIXct(strptime(VolumeBars$timestamp, "%Y-%m-%d %H:%M"))
  #VolumeBars$timestamp <- gsub(":00","",VolumeBars$timestamp) %>% as.POSIXct()
  VolumeBars$SpreadCm <- VolumeBars$SpreadCm / VolumeBars$ticks
  VolumeBars$ObservedPrice <- as.numeric(unlist(  
    VolumeBars['Price'] + VolumeBars['TickRule'] * (VolumeBars['Spread'] /2)))
  VolumeBars$Event <- ifelse(date(VolumeBars$timestamp) %in% date(News$date),"Yes","No")
  VolumeBars$Bar <- "Volume Bar"
  VolumeBars <- filter(VolumeBars, hour(timestamp) >= 10 & hour(timestamp) < 15)
  return(list(TickBars,VolumeBars))
}

hFplot <- function(quartile,i){
  # Select the days to test based on the Price volatility

  Desc2 <- within(Desc2, quartile <- as.integer(cut(Price_sd, quantile(Price_sd, probs=0:4/4),
                                                    include.lowest=TRUE)))

  # Fas <- Desc2[Desc2$date_col %in% date(News$date),]


  Q <- filter(Desc2,quartile == quartile)
  Q <-unique(Q[Q$date_col %in% date(News$date),]$date_col)
  if (i > length(Q)){
    cat("Choose a value between 1 and", length(Q))} 
  else {
    Vol <- filter(VolumeBars, date(VolumeBars$timestamp) == Q[i]) 
    Vol$timestamp <- hms::as.hms(Vol$timestamp)

    Tick <- filter(TickBars, date(TickBars$timestamp) == Q[i]) 
    Tick$timestamp <- hms::as.hms(Tick$timestamp)

    
    plot1 <- 
      ggplot(Vol, aes(x = timestamp)) +
      #  geom_line(aes(y = VWAP,color = "VWAP")) + 
        geom_point(aes(y = ticks,color = "Ticks per bar")) + 
        geom_area(aes(y = TickRule * 5))+ 
        geom_line(aes(y = Spread * 1000,color = "Spread"),linetype = "dashed") + 
        geom_vline(xintercept = 
                     hms::as_hms(strftime(grep(Q[i],News$date,value = TRUE), format="%H:%M:%S"))) +
       theme(legend.position = "bottom",
       axis.title.y=element_blank()) +
        labs(x = "Time of the day",title = "Volume Bars Behavior",
           subtitle = strftime(Q[i]))
       
      
    plot2 <- ggplot(Tick, aes(x = timestamp)) +
     # geom_line(aes(y = VWAP,color = "VWAP")) + 
      geom_point(aes(y = Volume / 5000,color = "Volume per bar")) +
      geom_area(aes(y = TickRule * 5))+ 
      geom_line(aes(y = Spread * 1000,color = "Spread"),linetype = "dashed") + 
      geom_vline(xintercept = 
                   hms::as_hms(strftime(grep(Q[i],News$date,value = TRUE), format="%H:%M:%S"))) +
       theme(legend.position = "bottom",
             axis.title.y=element_blank()) +
      labs(x = "Time of the day",title = "Tick Bars Behavior",
           subtitle = strftime(Q[i]))
      
    return(list(plot1,plot2))
  }
}

# generate tables for each day when news heppen on the middle of the day (to have enough pre/post data)
  # index 0 = news 

normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

WaveDf <- function(Bars, EventBinomial){
  
  dfWavePct <- list()
  dfWavePct2 <- data.frame()
  j <- Bars
  News <- News(as.character(j$Instrument[1]))
  if ( EventBinomial == "Yes"){
    eventDays <- unique(date(News$date))
    for (i in 1:length(eventDays)){
      eventDate <- eventDays[i]
      eventMinute <- hms::as_hms(strsplit(as.character(unique(News$date)[i]), " ")[[1]][2])
      if (eventDate %in% date(j$timestamp)){
          data <-  filter(j,date(j$timestamp) == eventDate)
          data$minute <- hms::as.hms(data$timestamp)
        
          rowWhenNews <- grep(eventMinute, data$minute)
          
          if (length(rowWhenNews) == 0){
            rowWhenNews <- which(abs( data$minute - eventMinute) == min(abs( data$minute - eventMinute)))
          }
          if (length(rowWhenNews) != 0){
            #data2 <- data.frame(lapply(select_if(data,is.numeric),normalize))
            data2 <- select_if(data,is.numeric)
            df <- data.frame()
            for (p in 1:ncol(data2)){
              for (k in 2:rowWhenNews){
                df[k,p] <- abs(round((data2[k,p] - data2[k-1,p]) / data2[k-1,p],5))
                #df$index[k] <- (rowWhenNews - (k)) * -1
              }
              for (k in rowWhenNews:(nrow(data2)-1)){
                df[k+1,p] <- abs(round((data2[k+1,p] - data2[k,p]) / data2[k,p],5))
                #df$index[k+1] <- (k + 1) - rowWhenNews
              }
            }
            names(df) <- names(data2)
            df$index <- 0
            for (k in 2:rowWhenNews){df$index[k] <- (rowWhenNews - (k)) * -1}
            for (k in rowWhenNews:(nrow(data2)-1)){df$index[k+1] <- (k + 1) - rowWhenNews}
            df$timestamp <- data$timestamp
            df$Event <- data$Event
            df$Bar <- data$Bar
            if (TRUE %in% (df$Bar == "Volume Bar")){
              df$Volume <- df$ticks
            }
            df$Instrument <- data$Instrument
            df <- df[-1,]
            dfWavePct[[i]] <- as.data.frame(df)
            dfWavePct2 <- rbind(dfWavePct2,df)
          } else {dfWavePct[[i]] <- NULL}
      }
    } 
  return(list(dfWavePct,dfWavePct2,rowWhenNews))
  }
  else if (EventBinomial == "No"){
    eventDays <- unique(
      date(filter(j,date(j$timestamp) !=  unique(date(News$date)))$timestamp))
    for (i in 1:eventDays){
      eventDate <- eventDays[i]
      if (eventDate %in% date(j$timestamp)){
        data <-  filter(j,date(j$timestamp) == eventDate)
        data2 <- select_if(data,is.numeric)
        df <- data.frame()
        for (p in 1:ncol(data2)){
          for (k in 2:(nrow(data2))){
             df[k,p] <- abs(round((data2[k,p] - data2[k-1,p]) / data2[k-1,p],5))
    #            df$index[k+1] <- (k + 1) - rowWhenNews
          }
        }
        names(df) <- names(data2)
        df$index <- 0
        for (k in 1:nrow(df)){df$index[k] <- k - round((nrow(df)/2))}
        df$timestamp <- data$timestamp
        df$Event <- data$Event
        df$Bar <- data$Bar
        if (TRUE %in% (df$Bar == "Volume Bar")){
          df$Volume <- df$ticks
        }
        df$Instrument <- data$Instrument
        df <- df[-1,]
        dfWavePct[[i]] <- df
        dfWavePct2 <- rbind(dfWavePct2,df)
    } else {dfWavePct[[i]] <- NULL}
    }
    return(dfWavePct2)
  }
}

indexDiff <- function(BarNumber){
  indexDiff <- data.frame()
  Bar <- unique(All$Bar)[[BarNumber]]
  data <- All[grep(unique(All$Bar)[[BarNumber]],All$Bar),]
  for (i in 1:length(sort(unique(data$index)))){
    
    i2 <- sort(unique(data$index))[i]
    data2 <- filter(data, index == i2)

    if (table(data2$Event) > 5){
      if(length(table(data2$Event) > 5) == 2){
        
        indexDiff[i,"bid"] <- summary(
          aov(bid ~ Event,data2))[[1]]$`Pr(>F)`[1]
        
        indexDiff[i,"ask"] <- summary(
          aov(ask ~ Event,data2))[[1]]$`Pr(>F)`[1]
        
        indexDiff[i,"bid_vol"] <- summary(
          aov(bid_vol ~ Event,data2))[[1]]$`Pr(>F)`[1]
        
        indexDiff[i,"ask_vol"] <- summary(
          aov(ask_vol ~ Event,data2))[[1]]$`Pr(>F)`[1]
        
        indexDiff[i,"Volume"] <- summary(
          aov(Volume ~ Event,data2))[[1]]$`Pr(>F)`[1]
        
        indexDiff[i,"Price"] <- summary(
          aov(Price ~ Event,data2))[[1]]$`Pr(>F)`[1]
        
        indexDiff[i,"MidPrice"] <- summary(
          aov(MidPrice ~ Event,data2))[[1]]$`Pr(>F)`[1]
        
        indexDiff[i,"Spread"] <- summary(
          aov(Spread ~ Event,data2))[[1]]$`Pr(>F)`[1]
        
        indexDiff[i,"SpreadCm"] <- summary(
          aov(SpreadCm ~ Event,data2))[[1]]$`Pr(>F)`[1]
        
        #indexDiff[i,"TickRule"] <- summary(
         # aov(TickRule ~ Event,filter(data, index == i )))[[1]]$`Pr(>F)`[1]
        
        indexDiff[i,"ObservedPrice"] <- summary(
          aov(ObservedPrice ~ Event,data2))[[1]]$`Pr(>F)`[1]
        
        indexDiff[i,"VWAP"] <- summary(
          aov(VWAP ~ Event,data2))[[1]]$`Pr(>F)`[1]
        
        indexDiff[i,"index"] <- i2
      }
    }
  }
  indexDiff <- indexDiff[! is.na(indexDiff),] %>%
    na.omit()
  indexDiff$Bar <- Bar
  return(indexDiff)
}


```


# Loading and Processing Data
```{r warning=FALSE}

  
  # FAANG Data ####

GoogleBars <- Bars("Google/Googleticks.csv","Google/Googlevols.csv",News("Google")) 
FacebookBars <- Bars("Facebook/Facebookticks.csv","Facebook/Facebookvols.csv",News("Facebook"))  
AppleBars <- Bars("Appleticks.csv","Applevols.csv",News("Apple"))  
NetflixBars <- Bars("Netflix/Netflixticks.csv","Netflix/Netflixvols.csv",News("Netflix"))  

# Transformations ####
All <- rbind(GoogleBars[[1]],GoogleBars[[2]],FacebookBars[[1]][-7],FacebookBars[[2]][-7],
             AppleBars[[1]],AppleBars[[2]],NetflixBars[[1]],NetflixBars[[2]])

Desc <- All

Desc2 <- All %>%
  mutate(date_col = date(timestamp)) %>%
  group_by(Event,Bar,date_col) %>%
  summarise_if(is.numeric,funs(n(),sd)) 
Desc2 <- Desc2[-c(4:15)]


VolumeBars <- rbind(GoogleBars[[2]],FacebookBars[[2]][-7],AppleBars[[2]],NetflixBars[[2]])
VolumeBars$Volume <- normalize(VolumeBars$ticks)
TickBars <- rbind(GoogleBars[[1]],FacebookBars[[1]][-7],AppleBars[[1]],NetflixBars[[1]])
TickBars$Volume <- normalize(TickBars$Volume)
Desc3 <- rbind(VolumeBars,TickBars)


All <- rbind(WaveDf(GoogleBars[[1]],"Yes")[[2]],WaveDf(GoogleBars[[2]],"Yes")[[2]],
             WaveDf(AppleBars[[1]],"Yes")[[2]],WaveDf(AppleBars[[2]],"Yes")[[2]],
             WaveDf(NetflixBars[[1]],"Yes")[[2]], WaveDf(NetflixBars[[2]],"Yes")[[2]],
             WaveDf(GoogleBars[[1]],"No"),WaveDf(GoogleBars[[2]],"No"),
             WaveDf(AppleBars[[1]],"No"),WaveDf(AppleBars[[2]],"No"),
             WaveDf(NetflixBars[[1]],"No"), WaveDf(NetflixBars[[2]],"No"))

indexDiff_Tick <- indexDiff(1)
indexDiff_Vol <- indexDiff(2)

indexDiff <- rbind(indexDiff_Tick,indexDiff_Vol)
# WaveDf(FacebookBars[[1]][-7],"Yes"),WaveDf(FacebookBars[[2]][-7],"Yes"),
# WaveDf(FacebookBars[[1]][-7],"No"),WaveDf(FacebookBars[[2]][-7],"No"),

```

# Graph 1: 
  This first graph compares the Volume volatilty on news release days vs non news release days. It serves as an introductory view, significance differences on Volume volatility on the prescence of news invites us to deeply analyze these differences.

```{r}
ggplot(Desc3)  +
  geom_violin(mapping = aes(x = Event, y = Volume, color = Event)) +
  facet_grid(.~Bar) +
  theme(axis.text.x=element_blank())+
  scale_y_log10() + 
  labs(title = "Compares the Volume volatilty on news release days vs non news release days.",
     subtitle = paste("Year 2019 \n",
                      "Tick Bar: p-value =",
                 round(summary(aov(Volume~Event, filter(Desc3,Bar == "Tick Bar")))[[1]]$`Pr(>F)`[1],4),
                 " >>> Confidence to Reject the Null Hypotesis \n",
                 "Volume Bar: p-value =",
                 round(summary(aov(Volume~Event, filter(Desc3,Bar == "Volume Bar")))[[1]]$`Pr(>F)`[1],4),
                 " >>> Confidence to Reject the Null Hypotesis"),
     caption = "Source: Dukascopy")

ggplot(Desc3)  +
  geom_violin(mapping = aes(x = Event, y = VWAP, color = Event)) +
  facet_grid(.~Bar) +
  theme(axis.text.x=element_blank())+
  scale_y_log10() + 
  labs(title = "Compares the Volume volatilty on news release days vs non news release days.",
     subtitle = paste("Year 2019 \n",
                      "Tick Bar: p-value =",
                 round(summary(aov(VWAP~Event, filter(Desc3,Bar == "Tick Bar")))[[1]]$`Pr(>F)`[1],4),
                 " >>> Confidence to Reject the Null Hypotesis \n",
                 "Volume Bar: p-value =",
                 round(summary(aov(VWAP~Event, filter(Desc3,Bar == "Volume Bar")))[[1]]$`Pr(>F)`[1],4),
                 " >>> Confidence to Reject the Null Hypotesis"),
     caption = "Source: Dukascopy")
```

# Graph 2: 
  Evaluates the intraday event based behavior of ticks per bar. Now, we strive to comprehend the behavior of the market at different times of the day, on the prescence of news vs no news days. 


```{r}
ggplot(Desc3, aes(x =factor(hour(timestamp)),Volume)) +
  facet_grid(Bar~Event) +
  geom_violin() +
  theme(axis.title.x=element_blank())+
  scale_y_log10() + 
  labs(title = "Evaluates the intraday event based Volume behavior.",
       subtitle = "Year 2019",
       caption = "Source: Dukascopy")
```

# Graph 3:
  Further, we strive to spot significance differences on the sample volatilty on the prescence of news. The hypotesis claims that on days of news release, the market should have more movement, therefore, the frequency of bars sampling should be significantly differnet than those days of no news release. 

```{r}


# Daily frequency of tick and volume spot news.
ggplot(filter(Desc2,date_col <= tail(sort(filter(Desc2,Event == "Yes")$date_col))[6]),
              aes(x = date_col)) + 
  geom_line(mapping = aes( y= VWAP_n , color = Bar)) + 
  geom_bar(stat = "identity", mapping = aes(y = SpreadCm_sd * 100)) +
  #geom_vline(xintercept = News$date) +
  theme(legend.position = "bottom") + 
  theme(axis.title.x=element_blank(),
        axis.text.x = element_blank())+
  facet_grid(Event~.)+
  labs(y = "Frequency", 
       title ="Daily frequency of tick and volume based on intraday news prescence",
       subtitle = paste("Year 2019 \n",
                        "Tick Bar: p-value =",
                   round(summary(aov(VWAP_n~Event, filter(Desc2,Bar == "Tick Bar")))[[1]]$`Pr(>F)`[1],4),
                   " >>> Confidence to Reject the Null Hypotesis \n",
                   "Volume Bar: p-value =",
                   round(
                     summary(aov(VWAP_n~Event, filter(Desc2,Bar == "Volume Bar")))[[1]]$`Pr(>F)`[1],4),
                   " >>> Confidence to Reject the Null Hypotesis"),
       caption = "Source: Dukascopy")

```

# Graph 4: 
  Compares the day aggregated volume standard deviations on events prescence days. Provides evidence that bid-ask spreads are significantly differnet in days of news release vs days of non news release.

```{r}
ggplot(Desc2)  +
  geom_boxplot(mapping = aes(y= SpreadCm_sd, x = Event, fill = Event)) +
  guides(fill=FALSE)+ 
  facet_grid(.~Bar) +
  scale_y_log10() +
  labs(y = "Spread",title = "Compares the day aggregated Spread volatility on events prescence days.",
   subtitle = paste("Year 2019 \n",
                    "Tick Bar: p-value =",
               round(summary(aov(SpreadCm_sd~Event, filter(Desc2,Bar == "Tick Bar")))[[1]]$`Pr(>F)`[1],4),
               " >>>  Fail to Reject the Null Hypotesis \n",
               "Volume Bar: p-value =",
               round(
                 summary(aov(SpreadCm_sd~Event, filter(Desc2,Bar == "Volume Bar")))[[1]]$`Pr(>F)`[1],4),
               " >>>  Fail to Reject the Null Hypotesis."),
   caption = "Source: Dukascopy")

ggplot(Desc2)  +
  geom_boxplot(mapping = aes(y= Volume_sd, x = Event, fill = Event)) +
  guides(fill=FALSE)+ 
  facet_grid(.~Bar) +
  scale_y_log10() +
  labs(y = "Volume",title = "Compares the day aggregated Volume volatility on events prescence days.",
   subtitle = paste("Year 2019 \n",
                    "Tick Bar: p-value =",
               round(summary(aov(Volume_sd~Event, filter(Desc2,Bar == "Tick Bar")))[[1]]$`Pr(>F)`[1],4),
               " >>>  Fail to Reject the Null Hypotesis \n",
               "Volume Bar: p-value =",
               round(summary(aov(Volume_sd~Event, filter(Desc2,Bar == "Volume Bar")))[[1]]$`Pr(>F)`[1],4),
               " >>> Confidence to Reject the Null Hypotesis"),
   caption = "Source: Dukascopy")

ggplot(Desc2)  +
  geom_boxplot(mapping = aes(y= VWAP_sd, x = Event, fill = Event)) +
  guides(fill=FALSE)+ 
  facet_grid(.~Bar) +
  scale_y_log10() +
  labs(y = "Price",title = "Compares the day aggregated Price volatility on events prescence days.",
   subtitle = paste("Year 2019 \n",
                    "Tick Bar: p-value =",
               round(summary(aov(VWAP_sd~Event, filter(Desc2,Bar == "Tick Bar")))[[1]]$`Pr(>F)`[1],4),
               " >>>  Fail to Reject the Null Hypotesis \n",
               "Volume Bar: p-value =",
               round(summary(aov(VWAP_sd~Event, filter(Desc2,Bar == "Volume Bar")))[[1]]$`Pr(>F)`[1],4),
               " >>>  Fail to Reject the Null Hypotesis."),
   caption = "Source: Dukascopy")


ggplot(Desc2)  +
  geom_boxplot(mapping = aes(y= VWAP_n, x = Event, fill = Event)) +
  guides(fill=FALSE)+ 
  facet_grid(.~Bar) +
  scale_y_log10() +
  labs(y = "Frequency",title = "Compares the day aggregated Frequency volatility on events prescence days.",
   subtitle = paste("Year 2019 \n",
                    "Tick Bar: p-value =",
               round(summary(aov(VWAP_n~Event, filter(Desc2,Bar == "Tick Bar")))[[1]]$`Pr(>F)`[1],4),
               " >>>  Confidence to Reject the Null Hypotesis \n",
               "Volume Bar: p-value =",
               round(summary(aov(VWAP_n~Event, filter(Desc2,Bar == "Volume Bar")))[[1]]$`Pr(>F)`[1],4),
               " >>>  Confidence to Reject the Null Hypotesis."),
   caption = "Source: Dukascopy")

```

# Graph 5:
  Aims to visualize "the wave" by plotting the index (distance from news release) vs the row-wise percent change. Significant difference on volume bars supports that these bars are better to classify the wave.

```{r}
lala <- All %>%
  group_by(Bar, Event, index) %>%
  summarise_if(is.numeric,funs(n(),mean)) %>%
  select(-c(5:16))
lala <- filter(lala, ticks_n >= 10 & index > -65 & index < 66)
lala$Session <- ifelse(lala$index <= 0,"Before","After")

ggplot(lala,aes(x = index)) +
  geom_line(aes(y = Volume_mean, color = "Volume")) + 
  geom_line(aes(y = VWAP_mean, color = "VWAP")) + 
  geom_line(aes(y = SpreadCm_mean, color = "Spread")) +
  geom_vline(xintercept = 0) + 
  facet_grid(Event~Bar) +
  scale_y_log10() +
  labs(y = "Pct Change",
     title = "Index Series of Percentage Change",
     subtitle = paste("Tick Bar Volume: p-value", 
                   round(summary(
                     aov(Volume_mean~ Event,data = filter(lala,Bar == "Tick Bar")))[[1]]$`Pr(>F)`[1],4),
                   " >>> Fail to Reject the Null Hypotesis \n",
                   "Volume Bar Volume: p-value =",
                   round(summary(
                     aov(
                       Volume_mean~ Event,data = filter(lala, Bar == "Volume Bar")))[[1]]$`Pr(>F)`[1],4),
                   ">>> Fail to Reject the Null Hypotesis \n",
                   "Tick Bar Price: p-value", 
                   round(summary(
                     aov(VWAP_mean~ Event,data = filter(lala,Bar == "Tick Bar")))[[1]]$`Pr(>F)`[1],4),
                   " >>> Fail to Reject the Null Hypotesis \n",
                   "Volume Bar Price: p-value =",
                   round(summary(
                     aov(
                       VWAP_mean~ Event,data = filter(lala, Bar == "Volume Bar")))[[1]]$`Pr(>F)`[1],4),
                   ">>> Fail to Reject the Null Hypotesis \n",
                   "Tick Bar Spread: p-value", 
                   round(summary(
                     aov(SpreadCm_mean~ Event,data = filter(lala,Bar == "Tick Bar")))[[1]]$`Pr(>F)`[1],4),
                   " >>> Fail to Reject the Null Hypotesis \n",
                   "Volume Bar Spread: p-value =",
                   round(summary(
                     aov(
                       SpreadCm_mean~ Event,data = 
                         filter(lala, Bar == "Volume Bar")))[[1]]$`Pr(>F)`[1],4),
                   ">>> Confidence to Reject the Null Hypotesis."),
       caption = "Source: Dukascopy")


```

# Graph 6:
  Spots p-values smaller than 0.05. These values are the wave confirmations. Spread and Volume parameters show significance difference at different indexes. Further analysis is necessary to personalize the analysis by instrument and day (to test the hypotesis that there are differnet news behaviors). 

```{r warning=FALSE}
ggplot(indexDiff, aes(x = index)) + 
  geom_point(aes(y = Volume,color = "Volume")) + 
  geom_point(aes(y = SpreadCm, color = "Spread")) +
  geom_point(aes(y = VWAP, color = "VWAP")) +
  geom_hline(yintercept = 0.05) + 
  facet_grid(.~Bar) +
  labs(y = "P-value", 
       title = "Evaluates indexe's significance difference by News or Non News Days",
       subtitle = "Visualizes the indexes which may identify as wave predictors",
       caption = "Source: Dukascopy")


```

# Graph 7:
  These vars visualizes market trends and the news days vs non news days significant different indexes (lines). These graphs helps us test the stastitially different behavior of informed traders (before news release) and the retail investors (after news release). 
  Note that these values may provide better comparison when tested on specific clusters of news days. 

```{r}

lala <- All %>%
  group_by(Bar, Event, index) %>%
  summarise_if(is.numeric,funs(n(),mean)) %>%
  select(-c(5:16))
lala$Session <- ifelse(lala$index <= 0,"Before","After")

ggplot(filter(lala,Event == "Yes"& Bar == "Tick Bar" & index %in% indexDiff_Tick$index),aes(x = index)) +
  geom_line(aes(y = Volume_mean, color = "Volume")) + 
  geom_line(aes(y = VWAP_mean, color = "VWAP")) + 
  geom_line(aes(y = SpreadCm_mean, color = "Spread")) +
  geom_vline(xintercept = 0) + 
  geom_vline(xintercept = sort(filter(indexDiff_Tick, SpreadCm < 0.05)$index),linetype="1F") +
  geom_vline(xintercept = sort(filter(indexDiff_Tick, Volume < 0.05)$index),linetype="dotdash") +
  scale_y_log10() +
  labs(y = "Percentage Change",
       title = "Identifies event vs no event significance difference (lines) \n  on the market intraday pct. change on event days, using Tick Bars",
       subtitle = paste("Before/After News Significance Difference: \n Volume p-Value",
                        round(summary(aov(Volume_mean~Session,
                                    filter(lala,Event == "Yes"& Bar == "Tick Bar" & 
                                             index %in% indexDiff_Tick$index)))[[1]]$`Pr(>F)`[1],4),
                        ">>> Fail to Reject the Null Hypotesis \n Spread p-Value",
                        round(summary(aov(SpreadCm_mean~Session,
                                    filter(lala,Event == "Yes"& Bar == "Tick Bar" & 
                                             index %in% indexDiff_Tick$index)))[[1]]$`Pr(>F)`[1],4),
                        ">>> Fail to Reject the Null Hypotesis"))
  
ggplot(filter(lala,Event == "Yes"& Bar == "Volume Bar"),aes(x = index)) +
  geom_line(aes(y = Volume_mean, color = "Volume")) + 
  geom_line(aes(y = VWAP_mean, color = "VWAP")) + 
  geom_line(aes(y = SpreadCm_mean, color = "Spread")) +
  geom_vline(xintercept = 0) + 
  geom_vline(xintercept = sort(filter(indexDiff_Vol, SpreadCm < 0.05)$index),linetype="1F") +
  geom_vline(xintercept = sort(filter(indexDiff_Vol, Volume < 0.05)$index),linetype="dotdash") +
  scale_y_log10() + 
  labs(y = "Percentage Change",
       title = "Identifies event vs no event significance difference (lines) \n  on the market intraday pct. change on event days, using Volume Bars",
       subtitle = paste("Before/After News Significance Difference: \n Volume p-Value",
                        round(summary(aov(Volume_mean~Session,
                                    filter(lala,Event == "Yes"& Bar == "Volume Bar" & 
                                             index %in% indexDiff_Tick$index)))[[1]]$`Pr(>F)`[1],4),
                        ">>> Fail to Reject the Null Hypotesis \n Spread p-Value",
                        round(summary(aov(SpreadCm_mean~Session,
                                    filter(lala,Event == "Yes"& Bar == "Volume Bar" & 
                                             index %in% indexDiff_Tick$index)))[[1]]$`Pr(>F)`[1],4),
                        ">>> Fail to Reject the Null Hypotesis"),
        = "Dotdash: Volume \n Dots: Spread")
  
  


```

```{r}#

```


# Clustering (Future Research)
```{r}#
# Measuring Date wave by assigning (Compare vs event days same bar's index mean)
#   wave start
#   wave length
#   strength (Significance difference on parameters vs Non Event Days Mean)
#   Behavior of before/after event sessions

# Cluster by those variables
# do Graph on chunck above for the different clusters


EachDayTest <- select(filter(All,Event == "Yes"),c(14,15,17,18))
EachDayTest$timestamp <- date(EachDayTest$timestamp)
EachDayTest <- EachDayTest %>% 
  distinct()
pepe <- filter(All,Event == "Yes")
pepe$timestamp <- date(pepe$timestamp)
EachDayTest <- inner_join(EachDayTest,pepe, by = c("index", "Bar","Instrument","timestamp"))
EachDayTest <- select(pepe,c(14,15,17,18))

main <- data.frame()
for (p in names(table(All$Instrument))){
  data <- filter(All, Instrument == p)
  for(f in names(table(EachDayTest$Bar))){
    data <- filter(data, Bar == f)
    for(j in 1:length(unique(data$timestamp))){  
      data <- filter(data,timestamp == unique(data$timestamp)[j])
      for (i in 1:nrow(data)){
        indexDay <- sort(data$index)[i]
        OtherDays <- filter(lala, Bar == data$Bar[1] & Event == "Yes" & index == indexDay)
        for(k in c(6:14,16,17)){
          Test <-  if(OtherDays[k] > filter(data, index == indexDay)[k]){1}else{0}
          main[i,names(data[k])] <- Test
        }
        for(k in 1:4){
          main[i,names(data[k])] <- data[i,k]
        }
      }
    }
  }
}
```


```{r warning=FALSE}#
for (j in names(table(All$Instrument))){
  data <- filter(All, Instrument == j)
  data$timestamp <- date(data$timestamp)
  for(f in names(table(data$Bar))){
    data2 <- filter(data, Bar == f)
    data3 <- select(data2,c(14,15)) %>% distinct
    data4 <- inner_join(data3,data2, by = c("index", "timestamp"))
    cat(j,f, dim(data3)[1], "vs", dim(data4)[1], "\n")
  }
}
```

